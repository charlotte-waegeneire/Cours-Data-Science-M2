{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b90a4c",
   "metadata": {},
   "source": [
    "# üßº Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b457019",
   "metadata": {},
   "source": [
    "This notebook includes practical demonstrations for:\n",
    "- Missing values\n",
    "- Outliers\n",
    "- Categorical encoding\n",
    "- Feature engineering\n",
    "- Scaling\n",
    "- Time series\n",
    "- Basic text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931725e",
   "metadata": {},
   "source": [
    "## üîç Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ddf973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\"],\n",
    "        \"Age\": [25, np.nan, 35, 40],\n",
    "        \"Gender\": [\"F\", \"M\", np.nan, \"M\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Fill missing values\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n",
    "df[\"Gender\"] = df[\"Gender\"].fillna(\"Unknown\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56311ae0",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Detecting and Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR method\n",
    "df_outliers = pd.DataFrame({\"Income\": [30000, 35000, 40000, 1200000]})\n",
    "Q1 = df_outliers[\"Income\"].quantile(0.25)\n",
    "Q3 = df_outliers[\"Income\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "df_outliers[\"CappedIncome\"] = np.clip(df_outliers[\"Income\"], lower, upper)\n",
    "df_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78103a47",
   "metadata": {},
   "source": [
    "## üî§ Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1db539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"City\": [\"Paris\", \"London\", \"Paris\", \"Berlin\"], \"Gender\": [\"F\", \"M\", \"F\", \"M\"]}\n",
    ")\n",
    "encoded = pd.get_dummies(df)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4684a7",
   "metadata": {},
   "source": [
    "## üß† Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1291b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"JoinDate\": pd.to_datetime([\"2019-01-01\", \"2021-06-15\", \"2020-03-01\"]),\n",
    "        \"Salary\": [40000, 50000, 60000],\n",
    "        \"Age\": [28, 32, 40],\n",
    "    }\n",
    ")\n",
    "df[\"TenureYears\"] = (pd.to_datetime(\"today\") - df[\"JoinDate\"]).dt.days // 365\n",
    "df[\"SalaryPerAge\"] = df[\"Salary\"] / df[\"Age\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6940c",
   "metadata": {},
   "source": [
    "## üìè Scaling Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfffb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.DataFrame({\"Feature1\": [1, 2, 3], \"Feature2\": [100, 200, 300]})\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(data)\n",
    "pd.DataFrame(scaled, columns=[\"Feature1\", \"Feature2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf831db6",
   "metadata": {},
   "source": [
    "## ‚è≥ Time Series Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe8bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "date_range = pd.date_range(start=\"2023-01-01\", periods=10, freq=\"D\")\n",
    "ts = pd.DataFrame({\"Date\": date_range, \"Value\": np.random.randint(10, 100, size=10)})\n",
    "ts.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Rolling average\n",
    "ts[\"RollingMean\"] = ts[\"Value\"].rolling(window=3).mean()\n",
    "# Lag feature\n",
    "ts[\"Lag1\"] = ts[\"Value\"].shift(1)\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a711fae",
   "metadata": {},
   "source": [
    "## üìù Basic Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "text = \"Data Science is AMAZING. Visit http://example.com for more! üòä\"\n",
    "text = text.lower()\n",
    "text = re.sub(r\"http\\S+|[^a-z\\s]\", \"\", text)\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "tokens = [w for w in tokens if w not in stopwords.words(\"english\")]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d2249",
   "metadata": {},
   "source": [
    "## üî° Vectorizing Text with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"Data science is the best!\",\n",
    "    \"I love data and machine learning.\",\n",
    "    \"Machine learning is a subset of AI.\",\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
