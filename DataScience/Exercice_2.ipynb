{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c418d3e2",
   "metadata": {},
   "source": [
    "# Pandas for Data Science\n",
    "This notebook demonstrates powerful capabilities of the Pandas library using a complex dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e901bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load employee data\n",
    "employee_data = pd.read_csv(\"employee_data.csv\")\n",
    "# Display the first few rows of the dataset\n",
    "employee_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c52707",
   "metadata": {},
   "source": [
    "### GroupBy and Multi-Level Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d875f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average salary and performance by Department and Team\n",
    "agg_employee_data = employee_data.groupby([\"Department\", \"Team\"]).agg(\n",
    "    {\n",
    "        \"Salary\": [\"mean\", \"max\", \"min\"],\n",
    "        \"PerformanceScore\": [\"mean\", \"std\"],\n",
    "        \"Age\": \"median\",\n",
    "    }\n",
    ")\n",
    "agg_employee_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe5319",
   "metadata": {},
   "source": [
    "### Filtering with Complex Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employees in Engineering, older than 40, with high performance\n",
    "filtered = employee_data[\n",
    "    (employee_data[\"Department\"] == \"Engineering\")\n",
    "    & (employee_data[\"Age\"] > 40)\n",
    "    & (employee_data[\"PerformanceScore\"] > 3.5)\n",
    "]\n",
    "filtered.sort_values(by=\"PerformanceScore\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e148be",
   "metadata": {},
   "source": [
    "### Using `apply()` with Custom Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30baf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_level(row):\n",
    "    years = 2025 - pd.to_datetime(row[\"JoinDate\"]).year\n",
    "    if years < 2:\n",
    "        return \"Junior\"\n",
    "    elif years < 5:\n",
    "        return \"Mid\"\n",
    "    else:\n",
    "        return \"Senior\"\n",
    "\n",
    "\n",
    "employee_data[\"ExperienceLevel\"] = employee_data.apply(experience_level, axis=1)\n",
    "employee_data[[\"Name\", \"JoinDate\", \"ExperienceLevel\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafba5b8",
   "metadata": {},
   "source": [
    "### Creating Pivot Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee7109",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.pivot_table(\n",
    "    employee_data,\n",
    "    index=\"Department\",\n",
    "    columns=\"ExperienceLevel\",\n",
    "    values=\"Salary\",\n",
    "    aggfunc=\"mean\",\n",
    ")\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4d1d7",
   "metadata": {},
   "source": [
    "### Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1992b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a new DataFrame with bonus info\n",
    "bonus_employee_data = pd.DataFrame(\n",
    "    {\n",
    "        \"EmployeeID\": np.random.choice(\n",
    "            employee_data[\"EmployeeID\"], size=50, replace=False\n",
    "        ),\n",
    "        \"Bonus\": np.random.randint(1000, 10000, size=50),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Merge with main data\n",
    "employee_data_merged = employee_data.merge(\n",
    "    bonus_employee_data, on=\"EmployeeID\", how=\"left\"\n",
    ")\n",
    "employee_data_merged[[\"Name\", \"Department\", \"Bonus\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6065948",
   "metadata": {},
   "source": [
    "###  Time Series: Resampling and Rolling Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime and set index in one step\n",
    "monthly_joins = (\n",
    "    employee_data.set_index(pd.to_datetime(employee_data[\"JoinDate\"]))\n",
    "    .resample(\"M\")[\"EmployeeID\"]\n",
    "    .count()\n",
    ")\n",
    "monthly_joins.plot(title=\"Monthly New Joiners\", figsize=(10, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b20ff",
   "metadata": {},
   "source": [
    "## Exercice: Sales Data Analysis\n",
    "\n",
    "You are provided with a dataset `sales_data.csv` containing retail transactions with the following columns:\n",
    "\n",
    "- `OrderID`: Order identifier  \n",
    "- `CustomerID`: Unique customer identifier  \n",
    "- `Product`: Product name  \n",
    "- `Category`: Product category  \n",
    "- `Quantity`: Number of units sold  \n",
    "- `Price`: Unit price  \n",
    "- `OrderDate`: Date of the order  \n",
    "- `Country`: Customer's country  \n",
    "\n",
    "### Tasks:\n",
    "\n",
    "1. **Basic Exploration**:\n",
    "   - Display the first 5 rows.\n",
    "   - Count missing values in each column.\n",
    "   - Print summary statistics for `Quantity` and `Price`.\n",
    "\n",
    "2. **Data Cleaning**:\n",
    "   - Remove rows where `Quantity` or `Price` is less than or equal to 0.\n",
    "   - Convert `OrderDate` to datetime format.\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "   - Create a new column `TotalAmount` = `Quantity` Ã— `Price`.\n",
    "   - Extract the `Month` and `DayOfWeek` from `OrderDate`.\n",
    "\n",
    "4. **Analysis**:\n",
    "   - What is the total revenue per `Country`? (Sort descending)\n",
    "   - What are the top 5 best-selling products by `Quantity`?\n",
    "   - How many unique customers are there in each `Country`?\n",
    "\n",
    "5. **Time Series Aggregation**:\n",
    "   - Plot total daily revenue (`OrderDate` vs. `TotalAmount`) using a line plot.\n",
    "   - Compute the monthly average quantity sold per category.\n",
    "\n",
    "> ðŸ’¡ Use `.groupby()`, `.agg()`, `.pivot_table()`, and visualization functions where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149cb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic Exploration\n",
    "sales_df = pd.read_csv(\"sales_data.csv\")\n",
    "print(sales_df.head())\n",
    "print(sales_df[[\"Quantity\", \"Price\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92973795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning\n",
    "sales_df = sales_df[(sales_df[\"Quantity\"] > 0) & (sales_df[\"Price\"] > 0)]\n",
    "sales_df[\"OrderDate\"] = pd.to_datetime(sales_df[\"OrderDate\"])\n",
    "sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f35c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Engineering\n",
    "sales_df[\"TotalAmount\"] = sales_df[\"Quantity\"] * sales_df[\"Price\"]\n",
    "sales_df[\"Month\"] = pd.to_datetime(sales_df[\"OrderDate\"]).dt.month\n",
    "sales_df[\"DayOfWeek\"] = pd.to_datetime(sales_df[\"OrderDate\"]).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Analysis\n",
    "total_revenue_per_country = (\n",
    "    sales_df.groupby(\"Country\")\n",
    "    .agg({\"TotalAmount\": \"sum\"})\n",
    "    .sort_values(by=\"TotalAmount\", ascending=False)\n",
    ")\n",
    "print(total_revenue_per_country)\n",
    "\n",
    "top_5_products = (\n",
    "    sales_df.groupby(\"Product\").agg({\"Quantity\": \"sum\"}).nlargest(5, \"Quantity\")\n",
    ")\n",
    "print(top_5_products)\n",
    "\n",
    "unique_customer_per_country = (\n",
    "    sales_df.groupby(\"Country\")\n",
    "    .agg({\"CustomerID\": \"nunique\"})\n",
    "    .sort_values(by=\"CustomerID\", ascending=False)\n",
    ")\n",
    "print(unique_customer_per_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Time Series Aggregation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "daily_revenue = sales_df.groupby(\"OrderDate\")[\"TotalAmount\"].sum()\n",
    "daily_revenue.plot(\n",
    "    kind=\"line\",\n",
    "    title=\"Total Daily Revenue\",\n",
    "    figsize=(12, 6),\n",
    "    xlabel=\"Order Date\",\n",
    "    ylabel=\"Total Revenue\",\n",
    ")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute monthly average quantity sold per category\n",
    "sales_df[\"YearMonth\"] = sales_df[\"OrderDate\"].dt.to_period(\"M\")\n",
    "monthly_avg_quantity = (\n",
    "    sales_df.groupby([\"YearMonth\", \"Category\"])[\"Quantity\"].mean().unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "print(\"Monthly Average Quantity Sold per Category:\")\n",
    "print(monthly_avg_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97338f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
